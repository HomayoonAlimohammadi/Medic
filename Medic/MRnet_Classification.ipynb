{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRnet_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GxMXhV2IYZvy",
        "VFwY7TxjYcQ3",
        "aGn56uoCL3Jy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv3tJmz9Muhl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5sC9klop-sy",
        "outputId": "6bd135b3-fa25-4d14-d4da-935c93002bdb"
      },
      "source": [
        "# !wget -P /content/drive/MyDrive/Medic/MRnet_Dataset http://download.cs.stanford.edu/deep/MRNet-v1.0.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-21 16:30:15--  http://download.cs.stanford.edu/deep/MRNet-v1.0.zip\n",
            "Resolving download.cs.stanford.edu (download.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to download.cs.stanford.edu (download.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6087523606 (5.7G) [application/zip]\n",
            "Saving to: ‘/content/drive/MyDrive/Medic/MRnet_Dataset/MRNet-v1.0.zip’\n",
            "\n",
            "MRNet-v1.0.zip      100%[===================>]   5.67G  4.61MB/s    in 19m 25s \n",
            "\n",
            "2021-10-21 16:49:40 (4.98 MB/s) - ‘/content/drive/MyDrive/Medic/MRnet_Dataset/MRNet-v1.0.zip’ saved [6087523606/6087523606]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0imrOhvUkASF"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "local_zip = '/content/drive/MyDrive/Medic/MRnet_Dataset/MRNet-v1.0.zip'\n",
        "zip = zipfile.ZipFile(local_zip, 'r')\n",
        "extraction_path = '/content/drive/MyDrive/Medic/MRnet_Dataset/Extracted/'\n",
        "members = zip.namelist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP5CFKyjhQ5Q"
      },
      "source": [
        "bad_files = ['__MACOSX/MRNet-v1.0/','__MACOSX/MRNet-v1.0/train/coronal/._.DS_Store','MRNet-v1.0/train/coronal/.DS_Store','__MACOSX/MRNet-v1.0/train/coronal/','__MACOSX/MRNet-v1.0/train/._.DS_Store','MRNet-v1.0/train/.DS_Store', 'MRNet-v1.0/train/sagittal/.DS_Store','__MACOSX/MRNet-v1.0/train/sagittal/','__MACOSX/MRNet-v1.0/train/sagittal/._.DS_Store','MRNet-v1.0/train/axial/.DS_Store','__MACOSX/MRNet-v1.0/train/','__MACOSX/MRNet-v1.0/train/axial/','__MACOSX/MRNet-v1.0/train/axial/._.DS_Store','MRNet-v1.0/.DS_Store','__MACOSX/MRNet-v1.0/._.DS_Store','MRNet-v1.0/valid/.DS_Store','__MACOSX/','__MACOSX/MRNet-v1.0/ ','__MACOSX/MRNet-v1.0/valid/','__MACOSX/MRNet-v1.0/valid/._.DS_Store']\n",
        "final_members = [member for member in members if member not in bad_files]\n",
        "csv_files = [member for member in members if member[-3:]=='csv']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lGGCwjKjTku"
      },
      "source": [
        "for member in final_members:\n",
        "  try:\n",
        "    zip.extract(member, path=extraction_path)\n",
        "  except:\n",
        "    print(member)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1ICE43jvl-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2491bb46-e6d3-42c9-9c8a-d30255aeb469"
      },
      "source": [
        "for member in csv_files:\n",
        "  try:\n",
        "    zip.extract(member, path=extraction_path)\n",
        "  except:\n",
        "    print(member)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRNet-v1.0/valid-abnormal.csv\n",
            "MRNet-v1.0/train-acl.csv\n",
            "MRNet-v1.0/train-meniscus.csv\n",
            "MRNet-v1.0/valid-acl.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxMXhV2IYZvy"
      },
      "source": [
        "# KNugget\n",
        "* https://www.kdnuggets.com/2019/11/deep-learning-image-classification-less-data.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5hgXjRHMQl_"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZh2D8ZiO8ik"
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
        "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxgQ76OuPAEH"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   rotation_range=15,\n",
        "                                   vertical_flip=True,\n",
        "                                   fill_mode='reflect',\n",
        "                                   data_format='channels_last',\n",
        "                                   brightness_range=[0.5, 1.5],\n",
        "                                   featurewise_center=True,\n",
        "                                   featurewise_std_normalization=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('dataset/train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('dataset/validation',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgeTUkQHPEtP"
      },
      "source": [
        "history = classifier.fit_generator(training_set,\n",
        "                         samples_per_epoch = 128,\n",
        "                         nb_epoch = 50,\n",
        "                         validation_data = test_set,\n",
        "                         nb_val_samples = 59)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8NW15jsPHAG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['validation'], loc='upper left')\n",
        "plt.title('validation loss vs epoch')\n",
        "plt.ylabel('validation loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvVthzyfPJK9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.legend(['validation'], loc='upper left')\n",
        "plt.title('validation accuracy vs epoch')\n",
        "plt.ylabel('validation accuracy')\n",
        "plt.xlabel('Epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFwY7TxjYcQ3"
      },
      "source": [
        "# AnalyticsVidhya\n",
        "* https://drive.google.com/file/d/1iQV5kKF_KGZL9ALx9MMXk_Lg7PklBLCE/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l1FaFCDYjEz"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0SDaVFaY1Ze"
      },
      "source": [
        "train = pd.read_csv('multi_label_train.csv')    # reading the csv file\n",
        "train.head()      # printing first five rows of the file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5oETzXAZB7k"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b8u-BWPZEwo"
      },
      "source": [
        "train_image = []\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    img = image.load_img('Multi_Label_dataset/Images/'+train['Id'][i]+'.jpg',target_size=(400,400,3))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img)\n",
        "X = np.array(train_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-NtyFz2ZGSS"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVSRhJlZH6M"
      },
      "source": [
        "plt.imshow(X[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZudikibZJNR"
      },
      "source": [
        "train['Genre'][2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws5G3oCGZKfb"
      },
      "source": [
        "y = np.array(train.drop(['Id', 'Genre'],axis=1))\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuYd7O5OZL86"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWFKGm2RZOGD"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(400,400,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(25, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kPegukVZPbM"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9FghBL4ZRkc"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oxBmpqlZTZ5"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhnYOI91ZeSR"
      },
      "source": [
        "* Download GOT: https://drive.google.com/file/d/1cfIE-42H4_UM-JERoctseLUpKwmd40YE/\n",
        "* Download Avengers: https://drive.google.com/file/d/1buNOcfo0Im2HmFH778dUwxven8Zzebtu/view"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OHqsMLPZaSR"
      },
      "source": [
        "img = image.load_img('GOT.jpg',target_size=(400,400,3))\n",
        "img = image.img_to_array(img)\n",
        "img = img/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlgNPKdcc1K6"
      },
      "source": [
        "classes = np.array(train.columns[2:])\n",
        "proba = model.predict(img.reshape(1,400,400,3))\n",
        "top_3 = np.argsort(proba[0])[:-4:-1]\n",
        "for i in range(3):\n",
        "    print(\"{}\".format(classes[top_3[i]])+\" ({:.3})\".format(proba[0][top_3[i]]))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHFGODsTc5Gu"
      },
      "source": [
        "img = image.load_img('avengers.jpeg',target_size=(400,400,3))\n",
        "img = image.img_to_array(img)\n",
        "img = img/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J21QOpLcc7AW"
      },
      "source": [
        "classes = np.array(train.columns[2:])\n",
        "proba = model.predict(img.reshape(1,400,400,3))\n",
        "top_3 = np.argsort(proba[0])[:-4:-1]\n",
        "for i in range(3):\n",
        "    print(\"{}\".format(classes[top_3[i]])+\" ({:.3})\".format(proba[0][top_3[i]]))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruW8x9CVc8-I"
      },
      "source": [
        "img = image.load_img('golmal.jpeg',target_size=(400,400,3))\n",
        "img = image.img_to_array(img)\n",
        "img = img/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xavk-Tt-c-xQ"
      },
      "source": [
        "classes = np.array(train.columns[2:])\n",
        "proba = model.predict(img.reshape(1,400,400,3))\n",
        "top_3 = np.argsort(proba[0])[:-4:-1]\n",
        "for i in range(3):\n",
        "    print(\"{}\".format(classes[top_3[i]])+\" ({:.3})\".format(proba[0][top_3[i]]))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PxpEbtAjmkO"
      },
      "source": [
        "Use Pre-Trained Models: https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGn56uoCL3Jy"
      },
      "source": [
        "# Kaggle Fruit Classification\n",
        "* https://www.kaggle.com/scratchpad/notebookd591b7784e/edit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNZVyE3nL5Lr"
      },
      "source": [
        "# Importing modules \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6extT0WL89N"
      },
      "source": [
        "# Processing training data\n",
        "# -> appending images in a list 'train_images'\n",
        "# -> appending labels in a list 'train_labels'\n",
        "\n",
        "train_images = []       \n",
        "train_labels = []\n",
        "shape = (200,200)  \n",
        "train_path = '../input/fruit-images-for-object-detection/train_zip/train'\n",
        "\n",
        "for filename in os.listdir('../input/fruit-images-for-object-detection/train_zip/train'):\n",
        "    if filename.split('.')[1] == 'jpg':\n",
        "        img = cv2.imread(os.path.join(train_path,filename))\n",
        "        \n",
        "        # Spliting file names and storing the labels for image in list\n",
        "        train_labels.append(filename.split('_')[0])\n",
        "        \n",
        "        # Resize all images to a specific shape\n",
        "        img = cv2.resize(img,shape)\n",
        "        \n",
        "        train_images.append(img)\n",
        "\n",
        "# Converting labels into One Hot encoded sparse matrix\n",
        "train_labels = pd.get_dummies(train_labels).values\n",
        "\n",
        "# Converting train_images to array\n",
        "train_images = np.array(train_images)\n",
        "\n",
        "# Splitting Training data into train and validation dataset\n",
        "x_train,x_val,y_train,y_val = train_test_split(train_images,train_labels,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRpL1FsZL_qD"
      },
      "source": [
        "# Processing testing data\n",
        "# -> appending images in a list 'test_images'\n",
        "# -> appending labels in a list 'test_labels'\n",
        "# The test data contains labels as well also we are appending it to a list but we are'nt going to use it while training.\n",
        "\n",
        "test_images = []\n",
        "test_labels = []\n",
        "shape = (200,200)\n",
        "test_path = '../input/fruit-images-for-object-detection/test_zip/test'\n",
        "\n",
        "for filename in os.listdir('../input/fruit-images-for-object-detection/test_zip/test'):\n",
        "    if filename.split('.')[1] == 'jpg':\n",
        "        img = cv2.imread(os.path.join(test_path,filename))\n",
        "        \n",
        "        # Spliting file names and storing the labels for image in list\n",
        "        test_labels.append(filename.split('_')[0])\n",
        "        \n",
        "        # Resize all images to a specific shape\n",
        "        img = cv2.resize(img,shape)\n",
        "        \n",
        "        test_images.append(img)\n",
        "        \n",
        "# Converting test_images to array\n",
        "test_images = np.array(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lTBrX37MA9U"
      },
      "source": [
        "# Visualizing Training data\n",
        "print(train_labels[0])\n",
        "plt.imshow(train_images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zs56a4VMB7B"
      },
      "source": [
        "# Visualizing Training data\n",
        "print(train_labels[4])\n",
        "plt.imshow(train_images[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOJJt4RwMC6j"
      },
      "source": [
        "# Creating a Sequential model\n",
        "model= Sequential()\n",
        "model.add(Conv2D(kernel_size=(3,3), filters=32, activation='tanh', input_shape=(200,200,3,)))\n",
        "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
        "model.add(MaxPool2D(2,2))\n",
        "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
        "model.add(MaxPool2D(2,2))\n",
        "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(20,activation='relu'))\n",
        "model.add(Dense(15,activation='relu'))\n",
        "model.add(Dense(4,activation = 'softmax'))\n",
        "    \n",
        "model.compile(\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['acc'],\n",
        "              optimizer='adam'\n",
        "             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN8YA4N2MEOn"
      },
      "source": [
        "# Model Summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0LQjTKfMFrz"
      },
      "source": [
        "# Training the model\n",
        "history = model.fit(x_train,y_train,epochs=50,batch_size=50,validation_data=(x_val,y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10E2M45NMGuJ"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yViMm1vMHx5"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiar3FltMJMs"
      },
      "source": [
        "# Evaluating model on validation data\n",
        "evaluate = model.evaluate(x_val,y_val)\n",
        "print(evaluate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP0pWuy5MKhE"
      },
      "source": [
        "# Testing predictions and the actual label\n",
        "checkImage = test_images[0:1]\n",
        "checklabel = test_labels[0:1]\n",
        "\n",
        "predict = model.predict(np.array(checkImage))\n",
        "\n",
        "output = { 0:'apple',1:'banana',2:'mixed',3:'orange'}\n",
        "\n",
        "print(\"Actual :- \",checklabel)\n",
        "print(\"Predicted :- \",output[np.argmax(predict)])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}